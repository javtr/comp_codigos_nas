{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Nombre de la serie  \\\n",
      "0                  ¿QUÉ HORA ES?   \n",
      "1         A Orillas Del Amazonas   \n",
      "2              Ángulos De Bogotá   \n",
      "3  Batalla Del Pantano De Vargas   \n",
      "4     Cali, la Sultana del Valle   \n",
      "\n",
      "                       Código versión restaurada        LTO  \\\n",
      "0                   VR F35mm 851242 QUÉ HORA ES?  Pendiente   \n",
      "1         VR F35mm 851304 A Orillas Del Amazonas   000124L8   \n",
      "2              VR F35mm 851303 Ángulos De Bogotá  Pendiente   \n",
      "3  VR F35mm 851011 Batalla del pantano de Vargas   000124L8   \n",
      "4     VR F35mm 851112 Cali, la Sultana del Valle   000173L8   \n",
      "\n",
      "  VERSIONES RESTAURADAS\\nSENALMEMORIA-10: 10.10.113.61  \\\n",
      "0                                                 Sí     \n",
      "1                                                 Sí     \n",
      "2                                                 Sí     \n",
      "3                                                 No     \n",
      "4                                                 No     \n",
      "\n",
      "            OBSERVACIONES DE VERIFICACIÓN EN LOS NAS  \\\n",
      "0  28/12/2023 La versión LQ esta en NAS 10 / Las ...   \n",
      "1  La versión LQ esta en NAS 10 / Las demas versi...   \n",
      "2  28/12/2023 La versión LQ esta en NAS 10 / Las ...   \n",
      "3                                        Masterizada   \n",
      "4              27/12/2023 Aún no estan en ningun NAS   \n",
      "\n",
      "                             NAS TODAS LAS VERSIONES  UBICACIÓN REAL  \n",
      "0  VERSIONES RESTAURADAS\\nSENALMEMORIA-10: 10.10....             NaN  \n",
      "1  VERSIONES RESTAURADAS\\nSENALMEMORIA-10: 10.10....             NaN  \n",
      "2  VERSIONES RESTAURADAS\\nSENALMEMORIA-10: 10.10....             NaN  \n",
      "3                                        Masterizada             NaN  \n",
      "4                                        Masterizada             NaN  \n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo Excel\n",
    "file_path = 'data/original/Ubicación actual de las Versiones Restauradas.xlsx'\n",
    "\n",
    "# Especifica el nombre o índice de la hoja que deseas importar\n",
    "sheet_name = 'VERSIONES RESTAURADAS'  # También puedes usar el índice de la hoja, por ejemplo: 0\n",
    "\n",
    "# Cargar la hoja especificada en un DataFrame\n",
    "df_verificacion = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df_verificacion.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Codigo                                              Resto\n",
      "0     VR F35mm 851242                                       QUÉ HORA ES?\n",
      "1     VR F35mm 851304                             A Orillas Del Amazonas\n",
      "2     VR F35mm 851303                                  Ángulos De Bogotá\n",
      "3     VR F35mm 851011                      Batalla del pantano de Vargas\n",
      "4     VR F35mm 851112                         Cali, la Sultana del Valle\n",
      "...               ...                                                ...\n",
      "1324  VR F16mm 802705                   Yuruparí Cap Cumbia sobre el río\n",
      "1325  VR F16mm 802706               Yuruparí Cap Las farotas de Talaigua\n",
      "1326  VR F16mm 802707  Yuruparí Cap Mompox, el ocaso del oro y del barro\n",
      "1327  VR F16mm 802708               Yuruparí Cap El Cristo negro de Tadó\n",
      "1328  VR F16mm 802709                Yuruparí Cap El Carnaval del Diablo\n",
      "\n",
      "[1329 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_codigos = pd.DataFrame()\n",
    "\n",
    "df_codigos[['Codigo', 'Resto']] = df_verificacion['Código versión restaurada'].str.extract(r'(^.*\\d{6})\\s*(.*)')\n",
    "\n",
    "# Mostrar el nuevo DataFrame con las dos columnas\n",
    "print(df_codigos[['Codigo', 'Resto']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Codigo existe    archivo  fila\n",
      "0    VR F35MM 851242     no       None   NaN\n",
      "1  UMT 205827 CLIP 1     si  nas_2.csv   0.0\n",
      "2          DV 270979     si  nas_2.csv   2.0\n"
     ]
    }
   ],
   "source": [
    "# Función para limpiar el código\n",
    "def clean_code(code):\n",
    "    return str(code).upper().strip()  # Convierte a mayúsculas y elimina espacios\n",
    "\n",
    "# Función para preprocesar los archivos CSV\n",
    "def preprocess_csv_files(folder_path):\n",
    "    preprocessed_data = []\n",
    "    # Iterar sobre los archivos en la carpeta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Cargar solo la primera columna (asumiendo que es la columna con los códigos)\n",
    "            df = pd.read_csv(file_path, usecols=[0], header=None)  # Cargar solo la primera columna\n",
    "            df['cleaned_code'] = df[0].apply(clean_code)  # Limpiar los códigos\n",
    "            preprocessed_data.append((filename, df[['cleaned_code']]))  # Guardar nombre de archivo y DataFrame limpio\n",
    "    return preprocessed_data\n",
    "\n",
    "# Función para crear un diccionario con los códigos\n",
    "def create_code_map(preprocessed_data):\n",
    "    code_map = {}\n",
    "    for filename, df in preprocessed_data:\n",
    "        for idx, row in df.iterrows():\n",
    "            code = row['cleaned_code']\n",
    "            if code not in code_map:\n",
    "                code_map[code] = []  # Inicializa una lista para múltiples ocurrencias\n",
    "            code_map[code].append((filename, idx))  # Guarda el archivo y la fila\n",
    "    return code_map\n",
    "\n",
    "# Función para verificar la existencia de un código\n",
    "def verificar_existencia(codigo):\n",
    "    cleaned_codigo = clean_code(codigo)  # Limpiar el código a buscar\n",
    "    if cleaned_codigo in code_map:  # Verificar si está en el diccionario\n",
    "        return \"si\", code_map[cleaned_codigo][0][0], code_map[cleaned_codigo][0][1]  # Retorna \"si\", el archivo y la fila\n",
    "    return \"no\", None, None  # Retorna \"no\" si no se encuentra\n",
    "\n",
    "# Ejecutar el preprocesamiento y la creación del diccionario\n",
    "folder_path = 'data/original/nas_csv'  # Ruta donde están los archivos CSV\n",
    "preprocessed_data = preprocess_csv_files(folder_path)  # Preprocesar los archivos CSV\n",
    "code_map = create_code_map(preprocessed_data)  # Crear el diccionario de códigos\n",
    "\n",
    "# Supongamos que df_codigos es tu DataFrame con los códigos a verificar\n",
    "df_codigos = pd.DataFrame({'Codigo': ['VR F35MM 851242', 'UMT 205827 CLIP 1', 'DV 270979']})\n",
    "\n",
    "# Aplicar la función para verificar existencia\n",
    "df_codigos[['existe', 'archivo', 'fila']] = df_codigos['Codigo'].apply(verificar_existencia).apply(pd.Series)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df_codigos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Codigo existe    archivo  fila extension\n",
      "0    VR F35MM 851242     no       None   NaN      None\n",
      "1  UMT 205827 CLIP 1     si  nas_2.csv   0.0       mov\n",
      "2          DV 270979     si  nas_2.csv   2.0       mov\n"
     ]
    }
   ],
   "source": [
    "# Función para limpiar el código\n",
    "def clean_code(code):\n",
    "    return str(code).upper().strip()  # Convierte a mayúsculas y elimina espacios\n",
    "\n",
    "# Función para preprocesar los archivos CSV\n",
    "def preprocess_csv_files(folder_path):\n",
    "    preprocessed_data = []\n",
    "    # Iterar sobre los archivos en la carpeta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Cargar solo las dos primeras columnas\n",
    "            df = pd.read_csv(file_path, usecols=[0, 1], header=None)  # Cargar solo la primera y segunda columna\n",
    "            df.columns = ['code', 'extension']  # Asignar nombres a las columnas\n",
    "            df['cleaned_code'] = df['code'].apply(clean_code)  # Limpiar los códigos\n",
    "            preprocessed_data.append((filename, df[['cleaned_code', 'extension']]))  # Guardar nombre de archivo y DataFrame limpio\n",
    "    return preprocessed_data\n",
    "\n",
    "# Función para crear un diccionario con los códigos\n",
    "def create_code_map(preprocessed_data):\n",
    "    code_map = {}\n",
    "    for filename, df in preprocessed_data:\n",
    "        for idx, row in df.iterrows():\n",
    "            code = row['cleaned_code']\n",
    "            if code not in code_map:\n",
    "                code_map[code] = []  # Inicializa una lista para múltiples ocurrencias\n",
    "            code_map[code].append((filename, idx, row['extension']))  # Guarda el archivo, la fila y la extensión\n",
    "    return code_map\n",
    "\n",
    "# Función para verificar la existencia de un código\n",
    "def verificar_existencia(codigo):\n",
    "    cleaned_codigo = clean_code(codigo)  # Limpiar el código a buscar\n",
    "    if cleaned_codigo in code_map:  # Verificar si está en el diccionario\n",
    "        return \"si\", code_map[cleaned_codigo][0][0], code_map[cleaned_codigo][0][1], code_map[cleaned_codigo][0][2]  # Retorna \"si\", el archivo, la fila y la extensión\n",
    "    return \"no\", None, None, None  # Retorna \"no\" si no se encuentra\n",
    "\n",
    "# Ejecutar el preprocesamiento y la creación del diccionario\n",
    "folder_path = 'data/original/nas_csv'  # Ruta donde están los archivos CSV\n",
    "preprocessed_data = preprocess_csv_files(folder_path)  # Preprocesar los archivos CSV\n",
    "code_map = create_code_map(preprocessed_data)  # Crear el diccionario de códigos\n",
    "\n",
    "# Supongamos que df_codigos es tu DataFrame con los códigos a verificar\n",
    "df_codigos = pd.DataFrame({'Codigo': ['VR F35MM 851242', 'UMT 205827 CLIP 1', 'DV 270979']})\n",
    "\n",
    "# Aplicar la función para verificar existencia\n",
    "df_codigos[['existe', 'archivo', 'fila', 'extension']] = df_codigos['Codigo'].apply(verificar_existencia).apply(pd.Series)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df_codigos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Codigo existe    archivo  fila extension\n",
      "0    VR F35MM 851242     no       None   NaN      None\n",
      "1  UMT 205827 CLIP 1     si  nas_2.csv   0.0       mov\n",
      "2          DV 270979     si  nas_2.csv   2.0       mov\n",
      "3          DV 277625     si  nas_2.csv   7.0       mov\n",
      "4         UMT 216433     si  nas_2.csv   8.0       mov\n",
      "5         C1P 242909     si  nas_2.csv   6.0     mp4  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Función para limpiar el código\n",
    "def clean_code(code):\n",
    "    return str(code).upper().strip()  # Convierte a mayúsculas y elimina espacios\n",
    "\n",
    "# Función para preprocesar los archivos CSV\n",
    "def preprocess_csv_files(folder_path):\n",
    "    preprocessed_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Cargar solo las dos primeras columnas\n",
    "            df = pd.read_csv(file_path, usecols=[0, 1], header=None)  # Cargar solo la primera y segunda columna\n",
    "            df.columns = ['code', 'extension']  # Asignar nombres a las columnas\n",
    "            df['cleaned_code'] = df['code'].apply(clean_code)  # Limpiar los códigos\n",
    "            preprocessed_data.append((filename, df[['cleaned_code', 'extension']]))  # Guardar nombre de archivo y DataFrame limpio\n",
    "    return preprocessed_data\n",
    "\n",
    "# Función para crear un diccionario con los códigos\n",
    "def create_code_map(preprocessed_data):\n",
    "    code_map = {}\n",
    "    for filename, df in preprocessed_data:\n",
    "        for idx, row in df.iterrows():\n",
    "            code = row['cleaned_code']\n",
    "            if code not in code_map:\n",
    "                code_map[code] = []  # Inicializa una lista para múltiples ocurrencias\n",
    "            code_map[code].append((filename, idx, row['extension']))  # Guarda el archivo, la fila y la extensión\n",
    "    return code_map\n",
    "\n",
    "# Función para verificar la existencia de un código\n",
    "def verificar_existencia(codigo):\n",
    "    cleaned_codigo = clean_code(codigo)  # Limpiar el código a buscar\n",
    "    if cleaned_codigo in code_map:  # Verificar si está en el diccionario\n",
    "        return \"si\", code_map[cleaned_codigo][0][0], code_map[cleaned_codigo][0][1], code_map[cleaned_codigo][0][2]  # Retorna \"si\", el archivo, la fila y la extensión\n",
    "    return \"no\", None, None, None  # Retorna \"no\" si no se encuentra\n",
    "\n",
    "# Ejecutar el preprocesamiento y la creación del diccionario\n",
    "folder_path = 'data/original/nas_csv'  # Ruta donde están los archivos CSV\n",
    "preprocessed_data = preprocess_csv_files(folder_path)  # Preprocesar los archivos CSV\n",
    "code_map = create_code_map(preprocessed_data)  # Crear el diccionario de códigos\n",
    "\n",
    "# Supongamos que df_codigos es tu DataFrame con los códigos a verificar\n",
    "df_codigos = pd.DataFrame({'Codigo': ['VR F35MM 851242', 'UMT 205827 CLIP 1', 'DV 270979', 'DV 277625', 'UMT 216433', 'C1P 242909']})\n",
    "\n",
    "# Aplicar la función para verificar existencia\n",
    "df_codigos[['existe', 'archivo', 'fila', 'extension']] = df_codigos['Codigo'].apply(verificar_existencia).apply(pd.Series)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df_codigos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Codigo existe     archivo  fila extension\n",
      "0    VR F35MM 851242     si  nas_10.csv   291       mov\n",
      "1  UMT 205827 CLIP 1     si   nas_2.csv     0       mov\n",
      "2          DV 270979     si   nas_2.csv     2       mov\n",
      "3          DV 277625     si   nas_2.csv     7       mov\n",
      "4         UMT 216433     si   nas_2.csv     8       mov\n",
      "5         C1P 242909     si   nas_2.csv     6     mp4  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Función para limpiar el código\n",
    "def clean_code(code):\n",
    "    return str(code).upper().strip()  # Convierte a mayúsculas y elimina espacios\n",
    "\n",
    "# Función para preprocesar los archivos CSV\n",
    "def preprocess_csv_files(folder_path):\n",
    "    preprocessed_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Cargar solo las dos primeras columnas\n",
    "            df = pd.read_csv(file_path, usecols=[0, 1], header=None)  # Cargar solo la primera y segunda columna\n",
    "            df.columns = ['code', 'extension']  # Asignar nombres a las columnas\n",
    "            df['cleaned_code'] = df['code'].apply(clean_code)  # Limpiar los códigos\n",
    "            preprocessed_data.append((filename, df[['cleaned_code', 'extension']]))  # Guardar nombre de archivo y DataFrame limpio\n",
    "    return preprocessed_data\n",
    "\n",
    "# Función para verificar la existencia de un código\n",
    "def verificar_existencia(codigo):\n",
    "    cleaned_codigo = clean_code(codigo)  # Limpiar el código a buscar\n",
    "    for key in code_map.keys():  # Iterar a través de los códigos preprocesados\n",
    "        if cleaned_codigo in key:  # Verificar si el código a buscar está en el código\n",
    "            return \"si\", code_map[key][0][0], code_map[key][0][1], code_map[key][0][2]  # Retorna \"si\", el archivo, la fila y la extensión\n",
    "    return \"no\", None, None, None  # Retorna \"no\" si no se encuentra\n",
    "\n",
    "# Ejecutar el preprocesamiento y la creación del diccionario\n",
    "folder_path = 'data/original/nas_csv'  # Ruta donde están los archivos CSV\n",
    "preprocessed_data = preprocess_csv_files(folder_path)  # Preprocesar los archivos CSV\n",
    "\n",
    "# Crear un diccionario con las claves como los códigos preprocesados\n",
    "code_map = {}\n",
    "for filename, df in preprocessed_data:\n",
    "    for idx, row in df.iterrows():\n",
    "        code = row['cleaned_code']\n",
    "        if code not in code_map:\n",
    "            code_map[code] = []  # Inicializa una lista para múltiples ocurrencias\n",
    "        code_map[code].append((filename, idx, row['extension']))  # Guarda el archivo, la fila y la extensión\n",
    "\n",
    "# Supongamos que df_codigos es tu DataFrame con los códigos a verificar\n",
    "df_codigos = pd.DataFrame({'Codigo': ['VR F35MM 851242', 'UMT 205827 CLIP 1', 'DV 270979', 'DV 277625', 'UMT 216433', 'C1P 242909']})\n",
    "\n",
    "# Aplicar la función para verificar existencia\n",
    "df_codigos[['existe', 'archivo', 'fila', 'extension']] = df_codigos['Codigo'].apply(verificar_existencia).apply(pd.Series)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df_codigos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Codigo existe     archivo  fila extension\n",
      "0    VR F35MM 851242     si  nas_10.csv   291       mov\n",
      "1  UMT 205827 CLIP 1     si   nas_2.csv     0       mov\n",
      "2          DV 270979     si   nas_2.csv     2       mov\n",
      "3          DV 277625     si   nas_2.csv     7       mov\n",
      "4         UMT 216433     si   nas_2.csv     8       mov\n",
      "5         C1P 242909     si   nas_2.csv     6     mp4  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Función para preprocesar los archivos CSV\n",
    "def preprocess_csv_files(folder_path):\n",
    "    preprocessed_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Cargar solo las dos primeras columnas\n",
    "            df = pd.read_csv(file_path, usecols=[0, 1], header=None)  # Cargar solo la primera y segunda columna\n",
    "            df.columns = ['code', 'extension']  # Asignar nombres a las columnas\n",
    "            preprocessed_data.append((filename, df))  # Guardar nombre de archivo y DataFrame sin limpiar\n",
    "    return preprocessed_data\n",
    "\n",
    "# Función para verificar la existencia de un código\n",
    "def verificar_existencia(codigo):\n",
    "    for key in code_map.keys():  # Iterar a través de los códigos preprocesados\n",
    "        # Crear una expresión regular para buscar el código en la cadena\n",
    "        pattern = re.escape(codigo)  # Escapar caracteres especiales en el código\n",
    "        if re.search(pattern, key, re.IGNORECASE):  # Ignorar mayúsculas/minúsculas\n",
    "            return \"si\", code_map[key][0][0], code_map[key][0][1], code_map[key][0][2]  # Retorna \"si\", el archivo, la fila y la extensión\n",
    "    return \"no\", None, None, None  # Retorna \"no\" si no se encuentra\n",
    "\n",
    "# Ejecutar el preprocesamiento y la creación del diccionario\n",
    "folder_path = 'data/original/nas_csv'  # Ruta donde están los archivos CSV\n",
    "preprocessed_data = preprocess_csv_files(folder_path)  # Preprocesar los archivos CSV\n",
    "\n",
    "# Crear un diccionario con las claves como los códigos preprocesados\n",
    "code_map = {}\n",
    "for filename, df in preprocessed_data:\n",
    "    for idx, row in df.iterrows():\n",
    "        code = row['code']\n",
    "        if code not in code_map:\n",
    "            code_map[code] = []  # Inicializa una lista para múltiples ocurrencias\n",
    "        code_map[code].append((filename, idx, row['extension']))  # Guarda el archivo, la fila y la extensión\n",
    "\n",
    "# Supongamos que df_codigos es tu DataFrame con los códigos a verificar\n",
    "df_codigos = pd.DataFrame({'Codigo': ['VR F35MM 851242', 'UMT 205827 CLIP 1', 'DV 270979', 'DV 277625', 'UMT 216433', 'C1P 242909']})\n",
    "\n",
    "# Aplicar la función para verificar existencia\n",
    "df_codigos[['existe', 'archivo', 'fila', 'extension']] = df_codigos['Codigo'].apply(verificar_existencia).apply(pd.Series)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df_codigos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
